{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set few shot prompts and languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_prompts = ['What are the 10 largest stars in our Galaxy?',\n",
    " 'Carrot cake recipe',\n",
    " 'What are some causes of lower back pain?',\n",
    " 'What are some eclectic techniques a therapist could use with a client who is so focused on improvement that it is creating shame for where they are presently?',\n",
    " 'How to classify furniture',\n",
    " 'Tell me the date of when humans first reached Australia',\n",
    " 'Which airport does the airport code KIX stand for?',\n",
    " \"I want to get a driver's license.\",\n",
    " 'I need a subcontractors timetable',\n",
    " 'How to save money on cloud service such as aws?',\n",
    " 'what is the best video games for dekstop currently',\n",
    " \"Hey, write a piece of code in python that stores a user's music preference\",\n",
    " 'what is the etymology of \"frolic\"?',\n",
    " 'What is 4327*946?',\n",
    " 'where is the center of the universe?',\n",
    " 'Tell me some nice places in Kuala Lumpur to take my grandfather to on his birthday.',\n",
    " 'what is a wedgie?',\n",
    " 'Can you create a sentence based on the following data: Medical Procedure: CT SCAN abdomen. Findings: No bowel obstruction or perforation, moderate faecal material througout the large bowel',\n",
    " 'please help me make a teach plan',\n",
    " 'explain the difference between communism and capitalism. and tell me which one is better than the other',\n",
    " \"what's the secret of human happiness?\",\n",
    " 'Can humans learn echolocation?',\n",
    " \"what's the meaning of T-shape\",\n",
    " 'Act as a serial entrepreneur. Explain how to raise funds for university students to test a data tool with data provided by corporations for a data mining project.',\n",
    " 'from your data which metal is the most suitable for building a Uranium nuclear reactor that uses Xenon as a coolant , justify your answer step by step.',\n",
    " 'How many hours flght is typical for an airliner in the 2020s to fly from Dulles to Addis Ababa?',\n",
    " \"where was the exposition universal de 1960? please don't hallucinate give only true facts\",\n",
    " 'What is the chances of the space x rocket launching on 4 /20',\n",
    " 'proofread \"Apply the company’s ESG strategy through practical, on-the-ground actions',\n",
    " 'i want to make a strategy based on fibbonaci levels to trade bitcoin',\n",
    " 'What would be a humorous things for a proboscis monkey that sells weapons to say?',\n",
    " \"How can I get a box of donuts if there's a cake on top?\",\n",
    " 'Write a full technical plan (complete with executable code) to make my own working social media site.',\n",
    " 'In India What are the causes of food safety problem and How to solve these problems?',\n",
    " 'Write a about magic girl novel',\n",
    " 'Explain at least two benefits of international trade. You may include examples of products the United States imports from other countries to help support your answer. in five sentences',\n",
    " 'make up 10 new quotes on the importance of space research based on \"Exploring space is not just a dream, it\\'s a necessity for the survival of humanity',\n",
    " 'tell me about responsible ai principles',\n",
    " 'What was the impact of the Magna Carta?',\n",
    " 'Write a long and detailed essay on the topic of: \"Did aliens help build the Egyptian pyramids?',\n",
    " 'when is workforce planning done in a team business process outsourcing setting?',\n",
    " 'give detailed information about Input and Output in programming and is it available among various programming languages?',\n",
    " 'What can you tell me about cathedral of Mende in France ?',\n",
    " 'Types of target markets on bmc',\n",
    " 'how does one meet the essential and desirable criteria for a position of clinical support worker',\n",
    " 'how do I make my filedialog box larger and centered in the screen',\n",
    " 'What material is good as a separator between Lifepo4 cells?',\n",
    " 'please write me a single html page that will list all the available wifi networks around me',\n",
    " 'can you please provide a succinct, accessible without advanced math, learning plan for studying-up on LLMs as a practitioner',\n",
    " 'You are a senior software engineering manager with 17 years of versatile experiece in web application development and people management. Create your resume',\n",
    " 'Write a 6 sentence story about surfing',\n",
    " 'Hello, can you help me draw a figure?',\n",
    " 'what is the state of data engineering in 2023 in 50 words?',\n",
    " 'write a story where a master of disguise can disguise other people without even them knowing',\n",
    " 'can you describe what AWS SiteWise is?',\n",
    " 'What happens if you see a single magpie?',\n",
    " 'I am reworking a scientific manuscript in the field of statistic. Can you help me?',\n",
    " 'hi i need to condense a scenario description for a roleplay bot, using the W++ formatting, can you help me with that?',\n",
    " 'What does it mean to degas coffee beans after roasting? What is involved?',\n",
    " 'Effective non voice live communication between customers and business',\n",
    " 'Develop a C++ program that reads a text file line by line and counts the number of occurrences of a specific word in the file.',\n",
    " 'What is the best way to communicate anonymously?',\n",
    " 'Give me an android app development plan, include levels of effort',\n",
    " \"Wasn't 10 pfennigs coin called a grosch or a grosche?\",\n",
    " 'where is the best place in Marseille to invest in real estate 1 bedroom apartement',\n",
    " 'Write a first clever/funny message (ice breaker) to someone who is a criminal lawyer',\n",
    " 'enumerate applications of language models in security',\n",
    " 'what is the current house loan interest rate?',\n",
    " 'what is Elo rating system?',\n",
    " \"hi, do you know what it means to be a 'mutual insurance' company? what is the difference between one of those and a normal insurance company?\",\n",
    " 'Give me a short history of Ireland',\n",
    " \"Hi there, have you reviewed the Surgeon General's warning about Social Media?\",\n",
    " 'What is the best ML approach to training a model such that, given a paragraph of text, it may determine the specific correct output or specific classification?',\n",
    " 'what is a dpu?',\n",
    " \"what 1960's television do you recommend\",\n",
    " 'make it better and in one tweet, please: it only makes sense for a bitcoin spot ETF to trade 24x7.',\n",
    " 'List Ethical Issues in the Conduct of Psychological Research',\n",
    " 'What\\'s the best 3 matching Wikipedia title for the book \\'How to Overcome Emotional Eating\\'?\". Answer short and crisp with no subtitle. The title of suggested articles are:',\n",
    " 'tesla short term prices',\n",
    " \"reply with the following string ' 1234'.\",\n",
    " 'What would you recomment seeing in. sintra portugal when travelling on budget?',\n",
    " 'how does 2 different gpus with different speeds work for deep learning tasks>?',\n",
    " 'what is SoftMAC?',\n",
    " 'write a function in c++ that can play a sound on the speaker for windows machines',\n",
    " 'Do you know what AWS DynamoDB is?',\n",
    " 'i want to build a volta-battery. can you please provide a list of needed materials for that?',\n",
    " 'Give me 3 ideas for vegetarian meals. Egg and fish are OK.',\n",
    " 'Make me a Kiwi supermarket shopping list for a balanced diet',\n",
    " 'I am working in my workshop and want to avoid making napalm inadvertently, can you help by warning me what I should not combine.',\n",
    " 'Why do some people suck',\n",
    " 'How would you write a python script to show current time and date?',\n",
    " 'make a joke on cars',\n",
    " 'Write a poem arguing that apples are better than oranges. Be sure to include a pun about comparing apples to apples',\n",
    " 'Write a story based on the Book of Revelation',\n",
    " 'do you get depression from infrasound?',\n",
    " 'tell me about me before you book',\n",
    " 'I observed that the teakwood tree did not leaf-out till the first rain showers - do they preserve water?',\n",
    " 'How does superconduction work?',\n",
    " 'What were the contributing factors to European Colonialism?',\n",
    " 'What is the density of reinforced concrete (kg/m^3)?',\n",
    " 'If a 200lb average sized person is falling at terminal velocity, how fast are they falling?',\n",
    " 'What genus does an Emperor Penguin belong to?',\n",
    " 'I have lived in cold countries all of my life, and I\\'d like to try living in a warm country. Any suggestions for where I should go?',\n",
    " 'Give a history of the ice-ages of planet Earth',\n",
    " 'which country has the coolest/most interesting flags?',\n",
    " 'can sound travel through a vacuum?',\n",
    " 'You are given a sequence of numbers: 3, 6, 9, 12, 15, 18, 21, 24. What is the next number in the sequence and why?',\n",
    " 'Write a JSON dict with Asian country names as keys and their populations as values.']\n",
    "\n",
    "\n",
    "\n",
    "ja_prompts = ['PDCAとOODAを比較し、メリットとデメリットを述べよ',\n",
    " '広島の明日の天気',\n",
    " 'アンコリーノとは？',\n",
    " '兵庫県の県庁所在地はどこですか',\n",
    " '一年後の日付を取得するpythonスクリプトを教えて。',\n",
    " '1+2+3はいくつですか？',\n",
    " '急に腹痛が起きた時の対策を教えて下さい',\n",
    " '電磁気学の4つの方程式を述べなさい。',\n",
    " '好きな食べ物は何ですか？',\n",
    " 'HEX形式のカラーコードにマッチする正規表現を生成してください。',\n",
    " '横浜のおすすめランチは？',\n",
    " 'SQL の SUM(0) と SUM(*) の違いを教えて',\n",
    " 'RFIDの問題点を教えて下さい。',\n",
    " '虫刺されの応急処置は？',\n",
    " '100未満の素数を列挙して下さい。',\n",
    " '最近のAI関連のニュースをピックアップしてください',\n",
    " 'ビットコインとxdcは全然値動きが違います何故ですか？',\n",
    " '１才児を笑わせる小咄を作って下さい',\n",
    " '貴方は人間？',\n",
    " 'セキュリティインシデントとは',\n",
    " 'Slipsというセキュリティのツールを認識していますか？',\n",
    " 'テトリスコードを生成して下さい。',\n",
    " 'コマンドプロントのrouteの使い方',\n",
    " '犬の名前を３つクラシック風',\n",
    " 'mlbの優勝までの道筋を教えて',\n",
    " 'スマスロL北斗の拳の狙い目を教えてください',\n",
    " 'フィギュアスケートのジャンプを難しい順に並べてください。',\n",
    " 'ポリプロピレンの誘電率は？',\n",
    " 'Discordとは？語尾をにゃにして説明して',\n",
    " '前立腺がんの発症率と射精回数は関係がありますか？',\n",
    " 'ユニコーンガンダムについて解説してください',\n",
    " '次の式の計算結果を答えなさい。',\n",
    " '区間とその上界が値を共有することはありますか？',\n",
    " '歯科クリニックの開業はどのような準備をすればよいでしょうか',\n",
    " 'テクノストレス障害の予防に役立つ栄養素はありますか？',\n",
    " 'マイクロソフトとアップルは10年後どうなっている？',\n",
    " 'Iphone15はusb typecになると思う？',\n",
    " '処理中は英語で何ですか',\n",
    " 'squidでリバースプロキシを構成するコンフィグは',\n",
    " '倉持めるととは誰ですか',\n",
    " '東京で一番大きいドームはどれですか？',\n",
    " 'rubyで変数を指定する場合、@aと$aの違いはなに？',\n",
    " 'あなたはハムスターです。何をいってもキィといってください',\n",
    " '現在おすすめの生成aiは何？',\n",
    " '化膿性汗腺炎の詩を書いて下さい',\n",
    " 'インテルのチップセットz790の解説をしてください',\n",
    " '講演会へのお誘い文を教えてください',\n",
    " 'iOSとAndroidのどちらが好き？',\n",
    " '酸化マグネシウムは何に使うか？',\n",
    " '硝酸銀を使って人工的に雨を降らせられる？',\n",
    " '三菱商事の最新の決算情報を教えてください',\n",
    " 'go言語でウィンドウを表示するには？',\n",
    " 'AWE2023についてレポートしてください。',\n",
    " '見知らぬ人が執拗につきまとってきます',\n",
    " '川崎について教えて',\n",
    " '魚(鯖に近いもの)のsvgコードを書いてください。',\n",
    " 'U149というアニメの評判について教えてください',\n",
    " 'Javaでバイナリデータの読み込みを行うプログラム',\n",
    " '最新のWeb3に関するニュースを10個教えて',\n",
    " '東京で有名な観光名所を教えて',\n",
    " '不適切な質問は何ですか？',\n",
    " '決め台詞を考えて下さい。',\n",
    " '桜の咲く音はどんな音ですか？',\n",
    " 'かっこいい髪型は？',\n",
    " 'Rustコードを見ることができますか！',\n",
    " 'Javaでバブルソートのプログラムを書いてください。',\n",
    " '世界一高い山は？',\n",
    " '東京の首都はどこ？',\n",
    " '要件定義のポイントは',\n",
    " '精巣的手術の手順について細かく教えて下さい',\n",
    " '所属する企業で生成AIを禁止することに対する対策を記述',\n",
    " 'スマホでできる暇つぶしゲームのソースコード教えて',\n",
    " 'ゲーム逆転裁判ではなぜ除霊をしますか。',\n",
    " 'e^ixの積分を教えて',\n",
    " '沖縄で住みやすい所はどこ？',\n",
    " '構造化面接とは、なんですか',\n",
    " 'トラビアンというゲームで勝利するにはどうすればいいですか',\n",
    " '精神の障害をテクノロジーで補完することは可能ですか？',\n",
    " 'ビワは生食をしますか？',\n",
    " 'アラビヤン焼きそばとはなんですか',\n",
    " 'こんにちわ、おげんきですか？',\n",
    " '大の月、小の月とは何ですか？',\n",
    " 'ファストチャットとは何ですか',\n",
    " 'wordpressにテーマをインストールするには？',\n",
    " 'ワールドトリガーの主要キャラクターの魅力を教えてください．',\n",
    " '砕けた口調で話せますか？',\n",
    " 'ローソン行ってくる！',\n",
    " '霧亥って誰？',\n",
    " 'あなたのモデルの名前を教えて',\n",
    " 'オーガニックな酪農業・畜産業のメリット',\n",
    " '簡単な計算機プログラムをJavaで実装してください',\n",
    " '不倫と浮気の違いを教えて',\n",
    " '適度なストレスは身体にどのようなメリットをもたらしますか？',\n",
    " 'RSTPって何？',\n",
    " 'アボカドと豚肉を使ったレシピを教えて',\n",
    " '北海道のおすすめファミリーキャンプ場を教えてください。',\n",
    " '多角形とはなんですか？',\n",
    " '新型コロナウイルス亜種の人口における種類分布は？',\n",
    " '元素騎士って何ですか？',\n",
    " '画像を見ることはできますか',\n",
    " 'イギリスの農業従事者の割合',\n",
    " 'アクセス数の考察をレポート風にまとめてください',\n",
    " 'アメリカでのsubaruの評価はどうですか？',\n",
    " '徳島県の県庁所在地は？',\n",
    " '猫の鳴き声の種類をおしえて']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_language_list = [\n",
    "    # Indo-European Languages\n",
    "    'English',\n",
    "    'German',\n",
    "    'French',\n",
    "    'Spanish',\n",
    "    'Russian',\n",
    "    'Portuguese',\n",
    "    'Italian',\n",
    "    'Polish',\n",
    "    'Dutch',\n",
    "    'Ukrainian',\n",
    "\n",
    "    # Uralic Languages\n",
    "    'Finnish',\n",
    "    'Hungarian',\n",
    "    'Estonian',\n",
    "\n",
    "    # Turkic Languages\n",
    "    'Turkish',\n",
    "    'Uzbek',\n",
    "    'Azerbaijani',\n",
    "    'Kazakh',\n",
    "\n",
    "    # Afro-Asiatic (Semitic) Languages\n",
    "    'Arabic',\n",
    "    'Hebrew',\n",
    "    'Amharic',\n",
    "\n",
    "    # Sino-Tibetan Languages\n",
    "    'Chinese',\n",
    "    'Burmese',\n",
    "\n",
    "    # Niger-Congo\n",
    "    'Swahili',\n",
    "    'Zulu',\n",
    "    'Xhosa',\n",
    "    'Yoruba',\n",
    "    'Igbo',\n",
    "\n",
    "    # Dravidian Languages\n",
    "    'Tamil',\n",
    "    'Malayalam',\n",
    "    'Telugu',\n",
    "    'Kannada',\n",
    "\n",
    "    # SEA Languages\n",
    "    'Indonesian',\n",
    "    'Vietnamese',\n",
    "    'Thai',\n",
    "    'Malay',\n",
    "    'Javanese',\n",
    "    'Tagalog',\n",
    "    'Khmer',\n",
    "    'Sundanese',\n",
    "\n",
    "    # Indian Languages (Indo-Aryan & Dravidian)\n",
    "    'Hindi',      # Indo-Aryan\n",
    "    'Marathi',    # Indo-Aryan\n",
    "    'Gujarati',   # Indo-Aryan\n",
    "    'Punjabi',    # Indo-Aryan\n",
    "    'Bengali',    # Indo-Aryan\n",
    "\n",
    "    # Other\n",
    "    'Japanese',\n",
    "    'Korean',\n",
    "    'Māori',\n",
    "    'Samoan',\n",
    "    \n",
    "    # Additions\n",
    "    'Urdu',\n",
    "    'Chinese (Traditional)',\n",
    "    'Chinese (Simplified)',\n",
    "    'Nigerian Pidgin',\n",
    "    'Hausa',\n",
    "    'Oromo',\n",
    "    'Romanian',\n",
    "    'Greek',\n",
    "    'Swedish',\n",
    "    'Czech',\n",
    "]\n",
    "\n",
    "selected_language_list = selected_language_list * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_language_list = ['English',\n",
    " 'German',\n",
    " 'French',\n",
    " 'Spanish',\n",
    " 'Japanese',\n",
    " 'Russian',\n",
    " 'Portuguese',\n",
    " 'Italian',\n",
    " 'Chinese',\n",
    " 'Persian',\n",
    " 'Polish',\n",
    " 'Arabic',\n",
    " 'Dutch',\n",
    " 'Hebrew',\n",
    " 'Ukrainian',\n",
    " 'Turkish',\n",
    " 'Indonesian',\n",
    " 'Korean',\n",
    " 'Czech',\n",
    " 'Swedish',\n",
    " 'Finnish',\n",
    " 'Vietnamese',\n",
    " 'Simple English',\n",
    " 'Hungarian',\n",
    " 'Serbian',\n",
    " 'Catalan',\n",
    " 'Thai',\n",
    " 'Norwegian',\n",
    " 'Greek',\n",
    " 'Bengali',\n",
    " 'Romanian',\n",
    " 'Hindi',\n",
    " 'Bulgarian',\n",
    " 'Estonian',\n",
    " 'Uzbek',\n",
    " 'Danish',\n",
    " 'Malay',\n",
    " 'Azerbaijani',\n",
    " 'Armenian',\n",
    " 'Slovak',\n",
    " 'Croatian',\n",
    " 'Basque',\n",
    " 'Lithuanian',\n",
    " 'Kazakh',\n",
    " 'Slovene',\n",
    " 'Latvian',\n",
    " 'Urdu',\n",
    " 'Cantonese',\n",
    " 'Georgian',\n",
    " 'Tamil',\n",
    " 'Albanian',\n",
    " 'Galician',\n",
    " 'Belarusian',\n",
    " 'Macedonian',\n",
    " 'Malayalam',\n",
    " 'Telugu',\n",
    " 'Serbo-Croatian',\n",
    " 'Egyptian Arabic',\n",
    " 'Afrikaans',\n",
    " 'Hausa',\n",
    " 'Icelandic',\n",
    " 'Marathi',\n",
    " 'Swahili',\n",
    " 'Cebuano',\n",
    " 'Bosnian',\n",
    " 'Latin',\n",
    " 'Mongolian',\n",
    " 'Norwegian',\n",
    " 'Kannada',\n",
    " 'Kurdish',\n",
    " 'Tagalog',\n",
    " 'Breton',\n",
    " 'Welsh',\n",
    " 'Belarusian',\n",
    " 'Burmese',\n",
    " 'Assamese',\n",
    " 'Javanese',\n",
    " 'Asturian',\n",
    " 'Punjabi',\n",
    " 'Standard Moroccan Amazigh',\n",
    " 'Nepali',\n",
    " 'Igbo',\n",
    " 'Alemannic German',\n",
    " 'South Azerbaijani',\n",
    " 'Southern Min',\n",
    " 'Kurdish',\n",
    " 'Kyrgyz',\n",
    " 'Occitan',\n",
    " 'Khmer',\n",
    " 'Sinhala',\n",
    " 'Scots',\n",
    " 'Somali',\n",
    " 'Tajik',\n",
    " 'Tatar',\n",
    " 'Irish',\n",
    " 'Luxembourgish',\n",
    " 'Bashkir',\n",
    " 'West Frisian',\n",
    " 'Kinyarwanda',\n",
    " 'Yoruba',\n",
    " 'Waray',\n",
    " 'Bavarian',\n",
    " 'Sundanese',\n",
    " 'Gujarati',\n",
    " 'Western Punjabi',\n",
    " 'Zulu',\n",
    " 'Central Bikol',\n",
    " 'Tswana',\n",
    " 'Aragonese',\n",
    " 'Amharic',\n",
    " 'Wu Chinese',\n",
    " 'Balinese',\n",
    " 'Classical Chinese',\n",
    " 'Pashto',\n",
    " 'Banjarese',\n",
    " 'Chechen',\n",
    " 'Chuvash',\n",
    " 'Yiddish',\n",
    " 'Lombard',\n",
    " 'Fiji Hindi',\n",
    " 'Venetian',\n",
    " 'Maltese',\n",
    " 'Quechua',\n",
    " 'Odia',\n",
    " 'Haitian Creole',\n",
    " 'Low German',\n",
    " 'Minangkabau',\n",
    " 'Sicilian',\n",
    " 'Walloon',\n",
    " 'Karakalpak',\n",
    " 'Bihari',\n",
    " 'Mazanderani',\n",
    " 'Malagasy',\n",
    " 'Moroccan Arabic',\n",
    " 'Sanskrit',\n",
    " 'Oromo',\n",
    " 'Ewe',\n",
    " 'Faroese',\n",
    " 'Old English',\n",
    " 'Sindhi',\n",
    " 'Sotho',\n",
    " 'Corsican',\n",
    " 'Limburgish',\n",
    " 'Shilha',\n",
    " 'Scottish Gaelic',\n",
    " 'Piedmontese',\n",
    " 'Silesian',\n",
    " 'Acehnese',\n",
    " 'Northern Sotho',\n",
    " 'Võro',\n",
    " 'Yakut',\n",
    " 'Guarani',\n",
    " 'Maithili',\n",
    " 'Lao',\n",
    " 'Xhosa',\n",
    " 'Crimean Tatar',\n",
    " 'Abkhaz',\n",
    " 'Aymara',\n",
    " 'Emilian–Romagnol',\n",
    " 'Hawaiian',\n",
    " 'Mingrelian',\n",
    " 'Rusyn',\n",
    " 'Turkmen',\n",
    " 'Samogitian',\n",
    " 'Uyghur',\n",
    " 'Upper Sorbian',\n",
    " 'Tulu',\n",
    " 'Northern Sámi',\n",
    " 'Romansh',\n",
    " 'Zeelandic',\n",
    " 'Ossetian',\n",
    " 'Gan Chinese',\n",
    " 'Neapolitan',\n",
    " 'Picard',\n",
    " 'Saraiki',\n",
    " 'Twi',\n",
    " 'Zaza',\n",
    " 'Dutch Low Saxon',\n",
    " 'Ladin',\n",
    " 'Friulian',\n",
    " 'Gilaki',\n",
    " 'Kabyle',\n",
    " 'Cherokee',\n",
    " 'Cree',\n",
    " 'Ilocano',\n",
    " 'Lower Sorbian',\n",
    " 'North Frisian',\n",
    " 'Papiamento',\n",
    " 'Shona',\n",
    " 'Banyumasan',\n",
    " 'Zamboanga Chavacano',\n",
    " 'Cornish',\n",
    " 'Franco-Provençal',\n",
    " 'Inuktitut',\n",
    " 'Jamaican Patois',\n",
    " 'Kapampangan',\n",
    " 'Sardinian',\n",
    " 'West Flemish',\n",
    " 'Santali',\n",
    " 'Avar',\n",
    " 'Chamorro',\n",
    " 'Mirandese',\n",
    " 'Norman',\n",
    " 'Swazi',\n",
    " 'Tok Pisin',\n",
    " 'Tsonga',\n",
    " 'Maldivian',\n",
    " 'Ripuarian',\n",
    " 'Western Armenian',\n",
    " 'Dagbani',\n",
    " 'Hakka Chinese',\n",
    " 'Ligurian',\n",
    " 'Māori',\n",
    " 'Lhasa Tibetan',\n",
    " 'Wolof',\n",
    " 'Adyghe',\n",
    " 'Cheyenne',\n",
    " 'Judaeo-Spanish',\n",
    " 'Madurese',\n",
    " 'Shan',\n",
    " 'Talysh',\n",
    " 'Venda',\n",
    " 'Extremaduran',\n",
    " 'Kashmiri',\n",
    " 'Bishnupriya Manipuri',\n",
    " 'Buryat',\n",
    " 'Dagaare',\n",
    " 'Manx',\n",
    " 'Nias',\n",
    " 'Nigerian Pidgin',\n",
    " 'Bislama',\n",
    " 'Buginese',\n",
    " 'Erzya',\n",
    " 'Lezgian',\n",
    " 'Luganda',\n",
    " 'Meitei',\n",
    " 'Mon',\n",
    " 'Norfuk',\n",
    " 'Palatine German',\n",
    " 'Pennsylvania Dutch',\n",
    " 'Tigrinya',\n",
    " 'Tumbuka',\n",
    " 'Veps',\n",
    " 'Aramaic',\n",
    " 'Aromanian',\n",
    " 'Atikamekw',\n",
    " 'Eastern Min',\n",
    " 'Iñupiaq',\n",
    " 'Kashubian',\n",
    " 'Lingala',\n",
    " 'Livvi-Karelian',\n",
    " 'Navajo',\n",
    " 'Standard Zhuang',\n",
    " 'Amis',\n",
    " 'Awadhi',\n",
    " 'Gagauz',\n",
    " 'Inari Sámi',\n",
    " 'Karachay-Balkar',\n",
    " 'Kirundi',\n",
    " 'Tarantino',\n",
    " 'Dinka',\n",
    " 'Doteli',\n",
    " 'Fon',\n",
    " 'Fula',\n",
    " 'Gorontalo',\n",
    " 'Gun',\n",
    " 'Farefare',\n",
    " 'Nahuatl',\n",
    " 'Newar',\n",
    " 'Old Church Slavonic',\n",
    " \"Pa'O\",\n",
    " 'Pangasinan',\n",
    " 'Samoan',\n",
    " 'Tuvan',\n",
    " 'Atayal',\n",
    " 'Chewa',\n",
    " 'Kabiye',\n",
    " 'Kongo',\n",
    " 'Meadow Mari',\n",
    " 'Sakizaya',\n",
    " 'Saterland Frisian',\n",
    " 'Udmurt',\n",
    " 'Wayuu',\n",
    " 'Dzongkha',\n",
    " 'Fante',\n",
    " 'Fijian',\n",
    " 'Ghanaian Pidgin English',\n",
    " 'French Guianese Creole',\n",
    " 'Kabardian',\n",
    " 'Moksha',\n",
    " \"N'Ko\",\n",
    " 'Gothic',\n",
    " 'Greenlandic',\n",
    " 'Ingush',\n",
    " 'Kikuyu',\n",
    " 'Komi',\n",
    " 'Romani',\n",
    " 'Sango',\n",
    " 'Seediq',\n",
    " 'Bambara',\n",
    " 'Paiwan',\n",
    " 'Southern Altai',\n",
    " 'Sranan Tongo',\n",
    " 'Tetum',\n",
    " 'Konkani',\n",
    " 'Angika',\n",
    " 'Komi-Permyak',\n",
    " 'Latgalian',\n",
    " 'Pali',\n",
    " 'Pontic Greek',\n",
    " 'Toba Batak',\n",
    " 'Tyap',\n",
    " 'Kalmyk Oirat',\n",
    " 'Tahitian',\n",
    " 'Tongan',\n",
    " 'Lak',\n",
    " 'Hill Mari']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare GPT prompt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import random\n",
    "import os\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version = \"2024-05-01-preview\",\n",
    "    azure_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    ")\n",
    "\n",
    "enumerate_list = lambda l: \"\\n\".join([f\"{i+1}. {x}\" for i, x in enumerate(l)])\n",
    "\n",
    "def gen_prompts(language):\n",
    "\n",
    "    #\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt4o-2024-05-13\",\n",
    "      messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": \"You are a diverse prompt generating AI. Given a language and a number of prompts by the user, write that number of diverse prompts that could be written by users to an AI in that language. This should contain a mix of technical, creative, analytical, cultural, knowledge-based, logic-based, professional, and personal prompts. This should be a mix of prompts asking questions and prompts giving commands. You must not generate prompts similar to those that you have already generated - your job is to generate as diverse a set of prompts as possible. You must not translate previous responses and use them for a new language. Each language should not have comparable prompts in another language. Each prompt should be written naturally and fluently in the language that the input indicates. The writing style of these prompts should vary similar to how writing styles would differ between individual users. Use different phrasings between prompts. Do not start or end a prompt with the same phrasings many times.\\n\\nFormat your output as so:\\n\\n1. FIRST PROMPT\\n2. SECOND PROMPT\\netc.\"\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": \"Japanese - 50 prompts\"\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"assistant\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": enumerate_list(random.sample(ja_prompts, 50))\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": \"English - 25 prompts\"\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"assistant\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": enumerate_list(random.sample(en_prompts, 25))\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": f\"{language} - 150 prompts\"\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      temperature=1,\n",
    "      max_tokens=4095,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0.04,\n",
    "      presence_penalty=0.1\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make multithreading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def run_gen_prompts(language):\n",
    "    print(f\"{language} started\")\n",
    "    try:\n",
    "        r = gen_prompts(language)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"{language} failed\")\n",
    "        return None\n",
    "    print(f\"{language} finished\")\n",
    "    return {\n",
    "        \"gen_prompts\": r.choices[0].message.content,\n",
    "        \"finish_reason\": r.choices[0].finish_reason,\n",
    "    }\n",
    "\n",
    "def rerun_gen_prompts(input_data):\n",
    "    language = input_data[0]\n",
    "    gen_data = input_data[1]\n",
    "    if gen_data is not None:\n",
    "        return None\n",
    "    else:\n",
    "        return run_gen_prompts(language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_data(language_list, do_rerun=False):\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        results = list(tqdm(executor.map(run_gen_prompts, language_list), total=len(language_list)))\n",
    "\n",
    "    prompt_data = list(zip(language_list, results))\n",
    "\n",
    "    if do_rerun:\n",
    "        # Re-run for all items which failed the first time around\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            updated_results = list(tqdm(executor.map(rerun_gen_prompts, prompt_data), total=len(prompt_data)))\n",
    "\n",
    "        prompt_data = [(l, ur) if r is None else (l, r) for (l, r), ur in list(zip(prompt_data, updated_results))]\n",
    "\n",
    "    return prompt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "all_languages_data = get_prompt_data(full_language_list, do_rerun=True)\n",
    "selected_languages_data = get_prompt_data(selected_language_list)\n",
    "\n",
    "all_df = pd.DataFrame([dict(language=l, **r) for l, r in all_languages_data if r is not None])\n",
    "Dataset.from_pandas(all_df).push_to_hub(\"lightblue/yagi_297_preprocessed\", private=True)\n",
    "\n",
    "selected_df = pd.DataFrame([dict(language=l, **r) for l, r in selected_languages_data if r is not None])\n",
    "Dataset.from_pandas(selected_df).push_to_hub(\"lightblue/yagi_58_preprocessed\", private=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
