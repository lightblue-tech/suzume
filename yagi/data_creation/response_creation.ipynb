{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tqdm.auto import tqdm, trange\n",
    "import time\n",
    "from openai import AzureOpenAI\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version = \"2024-05-01-preview\",\n",
    "    azure_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_responses(prompt_text):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt4o-2024-05-13\",\n",
    "      messages=[\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": prompt_text\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      temperature=1,\n",
    "      max_tokens=2048,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0.04,\n",
    "      presence_penalty=0.1\n",
    "    )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftlangdetect import detect\n",
    "\n",
    "def parse_prompts_from_list(yagi_df):\n",
    "    yagi_df.loc[:, \"prompt_list\"] = yagi_df.gen_prompts.str.split(\"\\n\").apply(\n",
    "        lambda x: [y[len(str(i+1)):].strip(\" .-ã€‚\") for i, y in enumerate(x) if y[:len(str(i+1))] == str(i+1)]\n",
    "    )\n",
    "\n",
    "    yagi_df.loc[:, \"prompt_list\"] = yagi_df[\"prompt_list\"].apply(lambda x: [y for y in x if len(y.strip()) > 0])\n",
    "\n",
    "    yagi_df = yagi_df.drop_duplicates(\"language\")[['language', 'finish_reason', 'prompt_list']].explode(\"prompt_list\")\n",
    "\n",
    "    yagi_df.loc[:, \"prompt_list\"] = yagi_df.prompt_list.str.strip()\n",
    "\n",
    "    return yagi_df\n",
    "\n",
    "def is_english_hi_confidence(text):\n",
    "    lang_res = detect(text=text, low_memory=False)\n",
    "    return lang_res[\"lang\"] == \"en\" and lang_res[\"score\"] > 0.8\n",
    "\n",
    "def is_japanese_hi_confidence(text):\n",
    "    lang_res = detect(text=text, low_memory=False)\n",
    "    return lang_res[\"lang\"] == \"ja\" and lang_res[\"score\"] > 0.8\n",
    "\n",
    "def filter_out_wrong_languages(yagi_df):\n",
    "    mask = yagi_df.apply(lambda x: is_english_hi_confidence(x[\"prompt_list\"]) and x[\"language\"] not in [\"Old English\", \"Simple English\", \"English\"], axis=1)\n",
    "    yagi_df = yagi_df[~mask]\n",
    "\n",
    "    mask = yagi_df.apply(lambda x: is_japanese_hi_confidence(x[\"prompt_list\"]) and x[\"language\"] not in [\"Japanese\"], axis=1)\n",
    "    yagi_df = yagi_df[~mask]\n",
    "\n",
    "    return yagi_df\n",
    "\n",
    "def pre_parse_df(yagi_df):\n",
    "    yagi_df = parse_prompts_from_list(yagi_df)\n",
    "    yagi_df = filter_out_wrong_languages(yagi_df)\n",
    "    return yagi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "def run_gen_responses(prompt_text):\n",
    "    try:\n",
    "        time.sleep(4 * random.random())\n",
    "        r = gen_responses(prompt_text)\n",
    "        return {\n",
    "            \"gen_prompts\": r.choices[0].message.content,\n",
    "            \"finish_reason\": r.choices[0].finish_reason,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Failed - {prompt_text}\")\n",
    "        print(e)\n",
    "        print()\n",
    "        return None\n",
    "\n",
    "def save_dataset(yagi_df, dataset_name):\n",
    "\n",
    "    chunk_size = 500\n",
    "\n",
    "    for i in trange(0, yagi_df.shape[0], chunk_size):\n",
    "\n",
    "        batch_df = yagi_df.iloc[i:i+chunk_size]\n",
    "        prompt_texts = batch_df[\"prompt_list\"].tolist()\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=14) as executor:\n",
    "            response_results = list(tqdm(executor.map(run_gen_responses, prompt_texts), total=len(prompt_texts)))\n",
    "\n",
    "        batch_df.loc[:, \"responses\"] = response_results\n",
    "        batch_df.to_parquet(f\"~/{dataset_name}/{str(i).zfill(6)}.parquet\")\n",
    "\n",
    "\n",
    "    yagi_dataset = load_dataset(\"parquet\", data_files={\"train\": f\"~/{dataset_name}/*.parquet\"}, split=\"train\")\n",
    "    yagi_dataset.push_to_hub(f\"lightblue/{dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "yagi_297_df = load_dataset(\"lightblue/yagi_297\", split=\"train\").to_pandas().dropna()\n",
    "yagi_297_df = pre_parse_df(yagi_df)\n",
    "\n",
    "save_dataset(yagi_297_df, \"yagi_297\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
