{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tqdm.auto import tqdm, trange\n",
    "import time\n",
    "from openai import AzureOpenAI\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version = \"2024-05-01-preview\",\n",
    "    azure_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_responses(prompt_text):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt4o-2024-05-13\",\n",
    "      messages=[\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": prompt_text\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      temperature=1,\n",
    "      max_tokens=2048,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0.04,\n",
    "      presence_penalty=0.1\n",
    "    )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def deduplicate_rows(yagi_df):\n",
    "    model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "\n",
    "    lang_df_list = []\n",
    "    for language, lang_df in yagi_df.groupby(\"language\"):\n",
    "        print(language)\n",
    "\n",
    "        sentences = lang_df.astype(str).prompt_list.tolist()\n",
    "\n",
    "        embeddings = model.encode(sentences,\n",
    "                                    batch_size=12,\n",
    "                                    max_length=8192, \n",
    "                                    )['dense_vecs']\n",
    "\n",
    "        # Move embeddings to GPU and calculate similarity\n",
    "        prompt_embeddings_cuda = torch.Tensor(embeddings).to(\"cuda\")\n",
    "        prompt_sim = prompt_embeddings_cuda @ prompt_embeddings_cuda.T\n",
    "        prompt_sim = prompt_sim.cpu().numpy()\n",
    "\n",
    "        # Make similarity 0 for top right traingle of similarity matrix so that we only remove one of high similarity pairs\n",
    "        np.fill_diagonal(prompt_sim, 0)\n",
    "        prompt_sim *= np.tri(*prompt_sim.shape)\n",
    "\n",
    "        max_similarity = 0.8\n",
    "        bad_item_idx_row, bad_item_idx_col = np.where(prompt_sim > 0.8)\n",
    "        unique_rows = set(np.unique(bad_item_idx_row))\n",
    "\n",
    "        mask = [True if i not in unique_rows else False for i in range(embeddings.shape[0])]\n",
    "\n",
    "        deduplicated_lang_df = lang_df[mask]\n",
    "\n",
    "        lang_df_list.append(deduplicated_lang_df)\n",
    "\n",
    "    all_df = pd.concat(lang_df_list)\n",
    "\n",
    "    all_df = all_df[~all_df.prompt_list.duplicated()]\n",
    "    all_df = all_df.dropna()\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftlangdetect import detect\n",
    "\n",
    "def parse_prompts_from_list(yagi_df):\n",
    "    yagi_df.loc[:, \"prompt_list\"] = yagi_df.gen_prompts.str.split(\"\\n\").apply(\n",
    "        lambda x: [y[len(str(i+1)):].strip(\" .-ã€‚\") for i, y in enumerate(x) if y[:len(str(i+1))] == str(i+1)]\n",
    "    )\n",
    "\n",
    "    yagi_df.loc[:, \"prompt_list\"] = yagi_df[\"prompt_list\"].apply(lambda x: [y for y in x if len(y.strip()) > 0])\n",
    "\n",
    "    yagi_df = yagi_df[['language', 'finish_reason', 'prompt_list']].explode(\"prompt_list\")\n",
    "\n",
    "    yagi_df.loc[:, \"prompt_list\"] = yagi_df.prompt_list.str.strip()\n",
    "\n",
    "    return yagi_df\n",
    "\n",
    "def is_english_hi_confidence(text):\n",
    "    lang_res = detect(text=text, low_memory=False)\n",
    "    return lang_res[\"lang\"] == \"en\" and lang_res[\"score\"] > 0.8\n",
    "\n",
    "def is_japanese_hi_confidence(text):\n",
    "    lang_res = detect(text=text, low_memory=False)\n",
    "    return lang_res[\"lang\"] == \"ja\" and lang_res[\"score\"] > 0.8\n",
    "\n",
    "def filter_out_wrong_languages(yagi_df):\n",
    "    mask = yagi_df.progress_apply(lambda x: isinstance(x[\"prompt_list\"], str) and is_english_hi_confidence(x[\"prompt_list\"]) and x[\"language\"] not in [\"Old English\", \"Simple English\", \"English\"], axis=1)\n",
    "    yagi_df = yagi_df[~mask]\n",
    "\n",
    "    mask = yagi_df.progress_apply(lambda x: isinstance(x[\"prompt_list\"], str) and is_japanese_hi_confidence(x[\"prompt_list\"]) and x[\"language\"] not in [\"Japanese\"], axis=1)\n",
    "    yagi_df = yagi_df[~mask]\n",
    "\n",
    "    return yagi_df\n",
    "\n",
    "def pre_parse_df(yagi_df, do_dedupe=False):\n",
    "    yagi_df = parse_prompts_from_list(yagi_df)\n",
    "    yagi_df = filter_out_wrong_languages(yagi_df)\n",
    "    \n",
    "    if do_dedupe:\n",
    "        yagi_df = deduplicate_rows(yagi_df)\n",
    "        \n",
    "    return yagi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "def run_gen_responses(prompt_text):\n",
    "    try:\n",
    "        time.sleep(4 * random.random())\n",
    "        r = gen_responses(prompt_text)\n",
    "        return {\n",
    "            \"gen_prompts\": r.choices[0].message.content,\n",
    "            \"finish_reason\": r.choices[0].finish_reason,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Failed - {prompt_text}\")\n",
    "        print(e)\n",
    "        print()\n",
    "        return None\n",
    "\n",
    "def save_dataset(yagi_df, dataset_name):\n",
    "\n",
    "    chunk_size = 500\n",
    "\n",
    "    for i in trange(0, yagi_df.shape[0], chunk_size):\n",
    "\n",
    "        batch_df = yagi_df.iloc[i:i+chunk_size]\n",
    "        prompt_texts = batch_df[\"prompt_list\"].tolist()\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=14) as executor:\n",
    "            response_results = list(tqdm(executor.map(run_gen_responses, prompt_texts), total=len(prompt_texts)))\n",
    "\n",
    "        batch_df.loc[:, \"responses\"] = response_results\n",
    "        batch_df.to_parquet(f\"~/{dataset_name}/{str(i).zfill(6)}.parquet\")\n",
    "\n",
    "\n",
    "    yagi_dataset = load_dataset(\"parquet\", data_files={\"train\": f\"~/{dataset_name}/*.parquet\"}, split=\"train\")\n",
    "    yagi_dataset.push_to_hub(f\"lightblue/{dataset_name}\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "yagi_297_df = load_dataset(\"lightblue/yagi_297_preprocessed\", split=\"train\").to_pandas().dropna()\n",
    "yagi_297_df = pre_parse_df(yagi_297_df)\n",
    "\n",
    "save_dataset(yagi_297_df, \"yagi_297\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "yagi_58_df = load_dataset(\"lightblue/yagi_58_preprocessed\", split=\"train\").to_pandas().dropna()\n",
    "yagi_58_df = pre_parse_df(yagi_58_df, do_dedupe=True)\n",
    "\n",
    "save_dataset(yagi_297_df, \"yagi_58\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
